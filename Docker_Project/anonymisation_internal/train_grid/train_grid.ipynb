{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7a35eb6-aaff-4a02-a834-d147d0196d08",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ckittask/envs/ria_ner36/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding=utf-8\n",
    "# Copyright 2020 The HuggingFace Team All rights reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\"\"\"\n",
    "Fine-tuning the library models for token classification.\n",
    "\"\"\"\n",
    "# You can also adapt this script on your own token classification task and datasets. Pointers for this are left as\n",
    "# comments.\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "\n",
    "import datasets\n",
    "import numpy as np\n",
    "from datasets import ClassLabel, load_dataset, load_metric\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForTokenClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForTokenClassification,\n",
    "    HfArgumentParser,\n",
    "    PreTrainedTokenizerFast,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "from transformers.utils import check_min_version\n",
    "from transformers.utils.versions import require_version\n",
    "from transformers.integrations import WandbCallback\n",
    "\n",
    "# Will error if the minimal version of Transformers is not installed. Remove at your own risks.\n",
    "check_min_version(\"4.10.0.dev0\")\n",
    "\n",
    "require_version(\"datasets>=1.8.0\", \"To fix: pip install -r examples/pytorch/token-classification/requirements.txt\")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.\n",
    "    \"\"\"\n",
    "\n",
    "    model_name_or_path: str = field(\n",
    "        metadata={\"help\": \"Path to pretrained model or model identifier from huggingface.co/models\"}\n",
    "    )\n",
    "    config_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"Pretrained config name or path if not the same as model_name\"}\n",
    "    )\n",
    "    tokenizer_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"Pretrained tokenizer name or path if not the same as model_name\"}\n",
    "    )\n",
    "    cache_dir: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"Where do you want to store the pretrained models downloaded from huggingface.co\"},\n",
    "    )\n",
    "    model_revision: str = field(\n",
    "        default=\"main\",\n",
    "        metadata={\"help\": \"The specific model version to use (can be a branch name, tag name or commit id).\"},\n",
    "    )\n",
    "    use_auth_token: bool = field(\n",
    "        default=False,\n",
    "        metadata={\n",
    "            \"help\": \"Will use the token generated when running `transformers-cli login` (necessary to use this script \"\n",
    "                    \"with private models).\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataTrainingArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to what data we are going to input our model for training and eval.\n",
    "    \"\"\"\n",
    "\n",
    "    dataset_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"The name of the dataset to use (via the datasets library).\"}\n",
    "    )\n",
    "    dataset_config_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"The configuration name of the dataset to use (via the datasets library).\"}\n",
    "    )\n",
    "    overwrite_cache: bool = field(\n",
    "        default=False, metadata={\"help\": \"Overwrite the cached training and evaluation sets\"}\n",
    "    )\n",
    "    preprocessing_num_workers: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"The number of processes to use for the preprocessing.\"},\n",
    "    )\n",
    "    max_seq_length: int = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"The maximum total input sequence length after tokenization. If set, sequences longer \"\n",
    "                    \"than this will be truncated, sequences shorter will be padded.\"\n",
    "        },\n",
    "    )\n",
    "    pad_to_max_length: bool = field(\n",
    "        default=False,\n",
    "        metadata={\n",
    "            \"help\": \"Whether to pad all samples to model maximum sentence length. \"\n",
    "                    \"If False, will pad the samples dynamically when batching to the maximum length in the batch. More \"\n",
    "                    \"efficient on GPU but very bad for TPU.\"\n",
    "        },\n",
    "    )\n",
    "    max_train_samples: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"For debugging purposes or quicker training, truncate the number of training examples to this \"\n",
    "                    \"value if set.\"\n",
    "        }\n",
    "    )\n",
    "    max_eval_samples: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"For debugging purposes or quicker training, truncate the number of evaluation examples to this \"\n",
    "                    \"value if set.\"\n",
    "        },\n",
    "    )\n",
    "    max_predict_samples: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"For debugging purposes or quicker training, truncate the number of prediction examples to this \"\n",
    "                    \"value if set.\"\n",
    "        },\n",
    "    )\n",
    "    label_all_tokens: bool = field(\n",
    "        default=False,\n",
    "        metadata={\n",
    "            \"help\": \"Whether to put the label for one word on all tokens of generated by that word or just on the \"\n",
    "                    \"one (in which case the other tokens will have a padding index).\"\n",
    "        },\n",
    "    )\n",
    "    return_tag_level_metrics: bool = field(\n",
    "        default=False,\n",
    "        metadata={\"help\": \"Whether to return all the tag metrics during evaluation or just the overall ones.\"},\n",
    "    )\n",
    "\n",
    "\n",
    "def main(config_file):\n",
    "    # See all possible arguments in src/transformers/training_args.py\n",
    "    # or by passing the --help flag to this script.\n",
    "    # We now keep distinct sets of args, for a cleaner separation of concerns.\n",
    "\n",
    "    parser = HfArgumentParser((ModelArguments, DataTrainingArguments, TrainingArguments))\n",
    "\n",
    "    model_args, data_args, training_args = parser.parse_json_file(\n",
    "            json_file=os.path.abspath(config_file))#'config/new_ner_config.json'))\n",
    "\n",
    "\n",
    "    # Hack, because otherwise we get value error\n",
    "    if isinstance(training_args.dataloader_drop_last, str):\n",
    "        if training_args.dataloader_drop_last.lower() in (\"false\", \"f\", \"no\", \"n\"):\n",
    "            training_args.dataloader_drop_last = False\n",
    "        else:\n",
    "            training_args.dataloader_drop_last = True\n",
    "    logger.info(\n",
    "        f\"Dataloader_drop_last: {training_args.dataloader_drop_last}, {type(training_args.dataloader_drop_last)}\")\n",
    "\n",
    "    # Setup logging\n",
    "    logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        handlers=[logging.StreamHandler(sys.stdout)],\n",
    "    )\n",
    "\n",
    "    log_level = training_args.get_process_log_level()\n",
    "    logger.setLevel(log_level)\n",
    "    datasets.utils.logging.set_verbosity(log_level)\n",
    "    transformers.utils.logging.set_verbosity(log_level)\n",
    "    transformers.utils.logging.enable_default_handler()\n",
    "    transformers.utils.logging.enable_explicit_format()\n",
    "\n",
    "    # Log on each process the small summary:\n",
    "    logger.warning(\n",
    "        f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"\n",
    "        + f\"distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"\n",
    "    )\n",
    "    logger.info(f\"Training/evaluation parameters {training_args}\")\n",
    "\n",
    "    # Detecting last checkpoint.\n",
    "    last_checkpoint = None\n",
    "    if os.path.isdir(training_args.output_dir) and training_args.do_train and not training_args.overwrite_output_dir:\n",
    "        last_checkpoint = get_last_checkpoint(training_args.output_dir)\n",
    "        if last_checkpoint is None and len(os.listdir(training_args.output_dir)) > 0:\n",
    "            raise ValueError(\n",
    "                f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"\n",
    "                \"Use --overwrite_output_dir to overcome.\"\n",
    "            )\n",
    "        elif last_checkpoint is not None and training_args.resume_from_checkpoint is None:\n",
    "            logger.info(\n",
    "                f\"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change \"\n",
    "                \"the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"\n",
    "            )\n",
    "\n",
    "    # Set seed before initializing model.\n",
    "    set_seed(training_args.seed)\n",
    "\n",
    "    assert data_args.dataset_name is not None\n",
    "    raw_datasets = load_dataset(\n",
    "        data_args.dataset_name, data_args.dataset_config_name, cache_dir=model_args.cache_dir\n",
    "    )\n",
    "\n",
    "    if training_args.do_train:\n",
    "        column_names = raw_datasets[\"train\"].column_names\n",
    "        features = raw_datasets[\"train\"].features\n",
    "    else:\n",
    "        column_names = raw_datasets[\"validation\"].column_names\n",
    "        features = raw_datasets[\"validation\"].features\n",
    "\n",
    "    text_column_name = column_names[1]\n",
    "    label_column_name = column_names[2]\n",
    "\n",
    "    # In the event the labels are not a `Sequence[ClassLabel]`, we will need to go through the dataset to get the\n",
    "    # unique labels.\n",
    "    def get_label_list(labels):\n",
    "        unique_labels = set()\n",
    "        for label in labels:\n",
    "            unique_labels.add(label)\n",
    "        label_list = list(unique_labels)\n",
    "        label_list.sort()\n",
    "        return label_list\n",
    "\n",
    "    if isinstance(features[label_column_name].feature, ClassLabel):\n",
    "        label_list = features[label_column_name].feature.names\n",
    "        # No need to convert the labels since they are already ints.\n",
    "        label_to_id = {i: i for i in range(len(label_list))}\n",
    "    else:\n",
    "        label_list = get_label_list(raw_datasets[\"train\"][label_column_name])\n",
    "        label_to_id = {l: i for i, l in enumerate(label_list)}\n",
    "    num_labels = len(label_list)\n",
    "\n",
    "    # Load pretrained model and tokenizer\n",
    "    #\n",
    "    # Distributed training:\n",
    "    # The .from_pretrained methods guarantee that only one local process can concurrently\n",
    "    # download model & vocab.\n",
    "    config = AutoConfig.from_pretrained(\n",
    "        model_args.config_name if model_args.config_name else model_args.model_name_or_path,\n",
    "        num_labels=num_labels,\n",
    "        label2id=label_to_id,\n",
    "        id2label={i: l for l, i in label_to_id.items()},\n",
    "        cache_dir=model_args.cache_dir,\n",
    "        revision=model_args.model_revision,\n",
    "        use_auth_token=True if model_args.use_auth_token else None,\n",
    "    )\n",
    "\n",
    "    tokenizer_name_or_path = model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path\n",
    "    if config.model_type in {\"gpt2\", \"roberta\"}:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\n",
    "            tokenizer_name_or_path,\n",
    "            cache_dir=model_args.cache_dir,\n",
    "            use_fast=True,\n",
    "            revision=model_args.model_revision,\n",
    "            use_auth_token=True if model_args.use_auth_token else None,\n",
    "            add_prefix_space=True,\n",
    "        )\n",
    "    else:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\n",
    "            tokenizer_name_or_path,\n",
    "            cache_dir=model_args.cache_dir,\n",
    "            use_fast=True,\n",
    "            revision=model_args.model_revision,\n",
    "            use_auth_token=True if model_args.use_auth_token else None,\n",
    "        )\n",
    "\n",
    "    model = AutoModelForTokenClassification.from_pretrained(\n",
    "        model_args.model_name_or_path,\n",
    "        from_tf=bool(\".ckpt\" in model_args.model_name_or_path),\n",
    "        config=config,\n",
    "        cache_dir=model_args.cache_dir,\n",
    "        revision=model_args.model_revision,\n",
    "        use_auth_token=True if model_args.use_auth_token else None,\n",
    "    )\n",
    "\n",
    "    # Tokenizer check: this script requires a fast tokenizer.\n",
    "    if not isinstance(tokenizer, PreTrainedTokenizerFast):\n",
    "        raise ValueError(\n",
    "            \"This example script only works for models that have a fast tokenizer. Checkout the big table of models \"\n",
    "            \"at https://huggingface.co/transformers/index.html#supported-frameworks to find the model types that meet this \"\n",
    "            \"requirement\"\n",
    "        )\n",
    "\n",
    "    # Preprocessing the dataset\n",
    "    # Padding strategy\n",
    "    padding = \"max_length\" if data_args.pad_to_max_length else False\n",
    "\n",
    "    # Tokenize all texts and align the labels with them.\n",
    "    def tokenize_and_align_labels(examples):\n",
    "        tokenized_inputs = tokenizer(\n",
    "            examples[text_column_name],\n",
    "            padding=padding,\n",
    "            truncation=True,\n",
    "            max_length=data_args.max_seq_length,\n",
    "            # We use this argument because the texts in our dataset are lists of words (with a label for each word).\n",
    "            is_split_into_words=True,\n",
    "        )\n",
    "        labels = []\n",
    "        for i, label in enumerate(examples[label_column_name]):\n",
    "            word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "            previous_word_idx = None\n",
    "            label_ids = []\n",
    "            for word_idx in word_ids:\n",
    "                # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
    "                # ignored in the loss function.\n",
    "                if word_idx is None:\n",
    "                    label_ids.append(-100)\n",
    "                # We set the label for the first token of each word.\n",
    "                elif word_idx != previous_word_idx:\n",
    "                    label_ids.append(label_to_id[label[word_idx]])\n",
    "                # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
    "                # the label_all_tokens flag.\n",
    "                else:\n",
    "                    label_ids.append(label_to_id[label[word_idx]] if data_args.label_all_tokens else -100)\n",
    "                previous_word_idx = word_idx\n",
    "\n",
    "            labels.append(label_ids)\n",
    "        tokenized_inputs[\"labels\"] = labels\n",
    "        return tokenized_inputs\n",
    "\n",
    "    if training_args.do_train:\n",
    "        if \"train\" not in raw_datasets:\n",
    "            raise ValueError(\"--do_train requires a train dataset\")\n",
    "        train_dataset = raw_datasets[\"train\"]\n",
    "        if data_args.max_train_samples is not None:\n",
    "            train_dataset = train_dataset.select(range(data_args.max_train_samples))\n",
    "        with training_args.main_process_first(desc=\"train dataset map pre-processing\"):\n",
    "            train_dataset = train_dataset.map(\n",
    "                tokenize_and_align_labels,\n",
    "                batched=True,\n",
    "                num_proc=data_args.preprocessing_num_workers,\n",
    "                load_from_cache_file=not data_args.overwrite_cache,\n",
    "                desc=\"Running tokenizer on train dataset\",\n",
    "            )\n",
    "\n",
    "    if training_args.do_eval:\n",
    "        if \"validation\" not in raw_datasets:\n",
    "            raise ValueError(\"--do_eval requires a validation dataset\")\n",
    "        eval_dataset = raw_datasets[\"validation\"]\n",
    "        if data_args.max_eval_samples is not None:\n",
    "            eval_dataset = eval_dataset.select(range(data_args.max_eval_samples))\n",
    "        with training_args.main_process_first(desc=\"validation dataset map pre-processing\"):\n",
    "            eval_dataset = eval_dataset.map(\n",
    "                tokenize_and_align_labels,\n",
    "                batched=True,\n",
    "                num_proc=data_args.preprocessing_num_workers,\n",
    "                load_from_cache_file=not data_args.overwrite_cache,\n",
    "                desc=\"Running tokenizer on validation dataset\",\n",
    "            )\n",
    "\n",
    "    if training_args.do_predict:\n",
    "        if \"test\" not in raw_datasets:\n",
    "            raise ValueError(\"--do_predict requires a test dataset\")\n",
    "        predict_dataset = raw_datasets[\"test\"]\n",
    "        if data_args.max_predict_samples is not None:\n",
    "            predict_dataset = predict_dataset.select(range(data_args.max_predict_samples))\n",
    "        with training_args.main_process_first(desc=\"prediction dataset map pre-processing\"):\n",
    "            predict_dataset = predict_dataset.map(\n",
    "                tokenize_and_align_labels,\n",
    "                batched=True,\n",
    "                num_proc=data_args.preprocessing_num_workers,\n",
    "                load_from_cache_file=not data_args.overwrite_cache,\n",
    "                desc=\"Running tokenizer on prediction dataset\",\n",
    "            )\n",
    "\n",
    "    # Data collator\n",
    "    data_collator = DataCollatorForTokenClassification(tokenizer, pad_to_multiple_of=8 if training_args.fp16 else None)\n",
    "\n",
    "    # Metrics\n",
    "    # TODO: rewrite the evaluation metric part\n",
    "    metric = load_metric(\"seqeval\")\n",
    "\n",
    "    def compute_metrics(p):\n",
    "        predictions, labels = p\n",
    "        predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "        # Remove ignored index (special tokens)\n",
    "        true_predictions = [\n",
    "            [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "            for prediction, label in zip(predictions, labels)\n",
    "        ]\n",
    "        true_labels = [\n",
    "            [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "            for prediction, label in zip(predictions, labels)\n",
    "        ]\n",
    "\n",
    "        results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "        if data_args.return_tag_level_metrics:\n",
    "            # Unpack nested dictionaries\n",
    "            final_results = {\n",
    "                \"precision\": results[\"overall_precision\"],\n",
    "                \"recall\": results[\"overall_recall\"],\n",
    "                \"f1\": results[\"overall_f1\"],\n",
    "                \"accuracy\": results[\"overall_accuracy\"],\n",
    "            }\n",
    "            for key, value in results.items():\n",
    "                if isinstance(value, dict):\n",
    "                    for n, v in value.items():\n",
    "                        final_results[f\"{key}_{n}\"] = v\n",
    "                else:\n",
    "                    final_results[key] = value\n",
    "            return final_results\n",
    "        else:\n",
    "            return {\n",
    "                \"precision\": results[\"overall_precision\"],\n",
    "                \"recall\": results[\"overall_recall\"],\n",
    "                \"f1\": results[\"overall_f1\"],\n",
    "                \"accuracy\": results[\"overall_accuracy\"],\n",
    "            }\n",
    "\n",
    "    early_stop_callback = EarlyStoppingCallback(early_stopping_patience=10, early_stopping_threshold=0.0001)\n",
    "    # wandb_callback = WandbCallback()\n",
    "\n",
    "    # Initialize our Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset if training_args.do_train else None,\n",
    "        eval_dataset=eval_dataset if training_args.do_eval else None,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[early_stop_callback]\n",
    "    )\n",
    "\n",
    "    # Training\n",
    "    if training_args.do_train:\n",
    "        checkpoint = None\n",
    "        if training_args.resume_from_checkpoint is not None:\n",
    "            checkpoint = training_args.resume_from_checkpoint\n",
    "        elif last_checkpoint is not None:\n",
    "            checkpoint = last_checkpoint\n",
    "        train_result = trainer.train(resume_from_checkpoint=checkpoint)\n",
    "        metrics = train_result.metrics\n",
    "        trainer.save_model()  # Saves the tokenizer too for easy upload\n",
    "\n",
    "        max_train_samples = (\n",
    "            data_args.max_train_samples if data_args.max_train_samples is not None else len(train_dataset)\n",
    "        )\n",
    "        metrics[\"train_samples\"] = min(max_train_samples, len(train_dataset))\n",
    "\n",
    "        trainer.log_metrics(\"train\", metrics)\n",
    "        trainer.save_metrics(\"train\", metrics)\n",
    "        trainer.save_state()\n",
    "\n",
    "    # Evaluation\n",
    "    if training_args.do_eval:\n",
    "        logger.info(\"*** Evaluate ***\")\n",
    "\n",
    "        metrics = trainer.evaluate()\n",
    "\n",
    "        max_eval_samples = data_args.max_eval_samples if data_args.max_eval_samples is not None else len(eval_dataset)\n",
    "        metrics[\"eval_samples\"] = min(max_eval_samples, len(eval_dataset))\n",
    "\n",
    "        trainer.log_metrics(\"eval\", metrics)\n",
    "        trainer.save_metrics(\"eval\", metrics)\n",
    "\n",
    "    # Predict\n",
    "    if training_args.do_predict:\n",
    "        logger.info(\"*** Predict ***\")\n",
    "\n",
    "        predictions, labels, metrics = trainer.predict(predict_dataset, metric_key_prefix=\"predict\")\n",
    "        predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "        # Remove ignored index (special tokens)\n",
    "        true_predictions = [\n",
    "            [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "            for prediction, label in zip(predictions, labels)\n",
    "        ]\n",
    "\n",
    "        trainer.log_metrics(\"predict\", metrics)\n",
    "        trainer.save_metrics(\"predict\", metrics)\n",
    "\n",
    "        # Save predictions\n",
    "        output_predictions_file = os.path.join(training_args.output_dir, \"predictions.txt\")\n",
    "        if trainer.is_world_process_zero():\n",
    "            with open(output_predictions_file, \"w\") as writer:\n",
    "                for prediction in true_predictions:\n",
    "                    writer.write(\" \".join(prediction) + \"\\n\")\n",
    "\n",
    "    if training_args.push_to_hub:\n",
    "        kwargs = {\"finetuned_from\": model_args.model_name_or_path, \"tasks\": \"token-classification\"}\n",
    "        if data_args.dataset_name is not None:\n",
    "            kwargs[\"dataset_tags\"] = data_args.dataset_name\n",
    "            if data_args.dataset_config_name is not None:\n",
    "                kwargs[\"dataset_args\"] = data_args.dataset_config_name\n",
    "                kwargs[\"dataset\"] = f\"{data_args.dataset_name} {data_args.dataset_config_name}\"\n",
    "            else:\n",
    "                kwargs[\"dataset\"] = data_args.dataset_name\n",
    "\n",
    "        trainer.push_to_hub(**kwargs)\n",
    "\n",
    "\n",
    "def _mp_fn(index):\n",
    "    # For xla_spawn (TPUs)\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12309ea5-f1a7-477c-8081-188642ad69d0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "The learning rate grid\n",
    "values were (5e-5, 3e-5, 1e-5, 5e-6, 3e-6) and the batch\n",
    "size grid values were (8, 16). The best model was found\n",
    "on the development set by using early stopping with the\n",
    "patience of 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "606d0cd9-92c9-43b4-80c8-29e7ac9cece9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json \n",
    "def write_config(batch_size, learning_rate, sequence_length): \n",
    "    f = open('config/new_ner_config.json', 'r')\n",
    "    data = json.load(f)\n",
    "    f.close()\n",
    "    data['learning_rate'] = learning_rate\n",
    "    data['per_device_train_batch_size'] = batch_size\n",
    "    data['per_device_eval_batch_size'] = batch_size\n",
    "    data['max_seq_length'] = sequence_length\n",
    "    data['cache_dir'] = 'estner_{}_{}_{}_cache'.format(sequence_length, learning_rate, batch_size)\n",
    "    data['output_dir'] = 'estner_{}_{}_{}'.format(sequence_length, learning_rate, batch_size)\n",
    "    f = open('config/new_ner_config_{}_{}_{}.json'.format(sequence_length, learning_rate, batch_size), 'w+')\n",
    "             \n",
    "    json.dump(data, f)\n",
    "    f.close()\n",
    "    \n",
    "\n",
    "def train_grid():\n",
    "    for bs in [8,16]: \n",
    "        for lr in [5e-5, 3e-5, 5e-6, 3e-6]: \n",
    "            for seq_len in [128, 512]: \n",
    "                write_config(bs , lr, seq_len)\n",
    "                main('config/new_ner_config_'+ str(seq_len) + '_' + str(lr) + '_'+ '.json')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3ac322b-b498-42a3-a2dc-26191474cef2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/ckittask/ria/config/new_ner_config_8_5e-05.json'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-27-9454fdb2f86d>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtrain_grid\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m<ipython-input-26-3f8691118e7b>\u001B[0m in \u001B[0;36mtrain_grid\u001B[0;34m()\u001B[0m\n\u001B[1;32m     21\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mseq_len\u001B[0m \u001B[0;32min\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;36m128\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m512\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     22\u001B[0m                 \u001B[0mwrite_config\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbs\u001B[0m \u001B[0;34m,\u001B[0m \u001B[0mlr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mseq_len\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 23\u001B[0;31m                 \u001B[0mmain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'config/new_ner_config_'\u001B[0m\u001B[0;34m+\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbs\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m'_'\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlr\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m'.json'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     24\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-25-7a1f3f9dbcf0>\u001B[0m in \u001B[0;36mmain\u001B[0;34m(config_file)\u001B[0m\n\u001B[1;32m    164\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    165\u001B[0m     model_args, data_args, training_args = parser.parse_json_file(\n\u001B[0;32m--> 166\u001B[0;31m             json_file=os.path.abspath(config_file))#'config/new_ner_config.json'))\n\u001B[0m\u001B[1;32m    167\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    168\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/envs/ria_ner36/lib/python3.6/site-packages/transformers/hf_argparser.py\u001B[0m in \u001B[0;36mparse_json_file\u001B[0;34m(self, json_file)\u001B[0m\n\u001B[1;32m    230\u001B[0m         \u001B[0mdataclass\u001B[0m \u001B[0mtypes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    231\u001B[0m         \"\"\"\n\u001B[0;32m--> 232\u001B[0;31m         \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mjson\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloads\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mPath\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mjson_file\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_text\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    233\u001B[0m         \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    234\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mdtype\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataclass_types\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/envs/ria_ner36/lib/python3.6/pathlib.py\u001B[0m in \u001B[0;36mread_text\u001B[0;34m(self, encoding, errors)\u001B[0m\n\u001B[1;32m   1194\u001B[0m         \u001B[0mOpen\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mfile\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mtext\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mread\u001B[0m \u001B[0mit\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mclose\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mfile\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1195\u001B[0m         \"\"\"\n\u001B[0;32m-> 1196\u001B[0;31m         \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'r'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mencoding\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mencoding\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0merrors\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0merrors\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1197\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1198\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/envs/ria_ner36/lib/python3.6/pathlib.py\u001B[0m in \u001B[0;36mopen\u001B[0;34m(self, mode, buffering, encoding, errors, newline)\u001B[0m\n\u001B[1;32m   1181\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_raise_closed\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1182\u001B[0m         return io.open(str(self), mode, buffering, encoding, errors, newline,\n\u001B[0;32m-> 1183\u001B[0;31m                        opener=self._opener)\n\u001B[0m\u001B[1;32m   1184\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1185\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mread_bytes\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/envs/ria_ner36/lib/python3.6/pathlib.py\u001B[0m in \u001B[0;36m_opener\u001B[0;34m(self, name, flags, mode)\u001B[0m\n\u001B[1;32m   1035\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_opener\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mflags\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0o666\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1036\u001B[0m         \u001B[0;31m# A stub for the opener argument to built-in open()\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1037\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_accessor\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mflags\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1038\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1039\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_raw_open\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mflags\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0o777\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/envs/ria_ner36/lib/python3.6/pathlib.py\u001B[0m in \u001B[0;36mwrapped\u001B[0;34m(pathobj, *args)\u001B[0m\n\u001B[1;32m    385\u001B[0m         \u001B[0;34m@\u001B[0m\u001B[0mfunctools\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwraps\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstrfunc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    386\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mwrapped\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpathobj\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 387\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mstrfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpathobj\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    388\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mstaticmethod\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mwrapped\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    389\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/home/ckittask/ria/config/new_ner_config_8_5e-05.json'"
     ]
    }
   ],
   "source": [
    "train_grid()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ria_ner36",
   "language": "python",
   "name": "ria_ner36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}